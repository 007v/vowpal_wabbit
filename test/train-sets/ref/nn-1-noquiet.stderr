Num weight bits = 18
learning rate = 0.5
initial_t = 0
power_t = 0.5
using no cache
Reading datafile = train-sets/0001.dat
num sources = 1
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
1.000000 1.000000            1            1.0   1.0000   0.0000       51
0.583420 0.166839            2            2.0   0.0000   0.4085      104
0.346631 0.109843            4            4.0   0.0000   0.3108      135
0.273133 0.199635            8            8.0   0.0000   0.2905      146
0.261001 0.248869           16           16.0   1.0000   0.2920       24
0.251532 0.242063           32           32.0   0.0000   0.3429       32
0.244867 0.238203           64           64.0   0.0000   0.3534       61
0.243891 0.242915          128          128.0   1.0000   0.5381      106

finished run
number of examples per pass = 200
passes used = 1
weighted example sum = 200.000000
weighted label sum = 91.000000
average loss = 0.230763
best constant = 0.455000
best constant's loss = 0.247975
total feature number = 15482
