using l1 regularization = 0.01
final_regressor = models/mask.model
Num weight bits = 18
learning rate = 0.5
initial_t = 0
power_t = 0.5
using no cache
Reading datafile = train-sets/0001.dat
num sources = 1
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
0.000000 0.000000            1            1.0   1.0000   1.0000       51
0.000000 0.000000            2            2.0   0.0000   0.0000      104
0.000000 0.000000            4            4.0   0.0000   0.0000      135
0.129727 0.259454            8            8.0   0.0000   0.1854      146
0.192680 0.255633           16           16.0   1.0000   0.3144       24
0.213941 0.235202           32           32.0   0.0000   0.2189       32
0.220157 0.226373           64           64.0   0.0000   0.2116       61
0.226108 0.232060          128          128.0   1.0000   0.4550      106

finished run
number of examples per pass = 200
passes used = 1
weighted example sum = 200.000000
weighted label sum = 91.000000
average loss = 0.218993
best constant = 0.455000
best constant's loss = 0.247975
total feature number = 15482
