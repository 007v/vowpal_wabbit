using l1 regularization = 0.01
final_regressor = models/mask.model
Num weight bits = 18
learning rate = 0.5
initial_t = 0
power_t = 0.5
using no cache
Reading datafile = train-sets/0001.dat
num sources = 1
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
1.000000 1.000000            1            1.0   1.0000   0.0000       51
0.513248 0.026497            2            2.0   0.0000   0.1628      104
0.262821 0.012393            4            4.0   0.0000   0.0559      135
0.237622 0.212423            8            8.0   0.0000   0.2042      146
0.243327 0.249031           16           16.0   1.0000   0.3163       24
0.237459 0.231592           32           32.0   0.0000   0.2107       32
0.233102 0.228745           64           64.0   0.0000   0.2046       61
0.233305 0.233508          128          128.0   1.0000   0.4661      106

finished run
number of examples per pass = 200
passes used = 1
weighted example sum = 200.000000
weighted label sum = 91.000000
average loss = 0.224163
best constant = 0.455000
best constant's loss = 0.247975
total feature number = 15482
