warning: multiplicative --progress <float>: 0.5 is <= 1.0: adding 1.0
Num weight bits = 18
learning rate = 0.5
initial_t = 0
power_t = 0.5
using no cache
Reading datafile = train-sets/0001.dat
num sources = 1
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
0.000000 0.000000            1            1.0   1.0000   1.0000       51
0.000000 0.000000            2            2.0   0.0000   0.0000      104
0.000000 0.000000            3            3.0   0.0000   0.0000       57
0.000000 0.000000            5            5.0   0.0000   0.0000      131
0.129823 0.346194            8            8.0   0.0000   0.1869      146
0.153922 0.202121           12           12.0   0.0000   0.1857      209
0.204936 0.306963           18           18.0   0.0000   0.3403       29
0.217928 0.243911           27           27.0   0.0000   0.2214      197
0.207262 0.186692           41           41.0   0.0000   0.2844       20
0.221569 0.249501           62           62.0   0.0000   0.4176       96
0.207163 0.178352           93           93.0   1.0000   0.8652       58
0.211787 0.220935          140          140.0   0.0000   0.3311       82

finished run
number of examples per pass = 200
passes used = 1
weighted example sum = 200.000000
weighted label sum = 91.000000
average loss = 0.191325
best constant = 0.455000
best constant's loss = 0.247975
total feature number = 15482
