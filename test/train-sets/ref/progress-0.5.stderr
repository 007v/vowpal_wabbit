warning: multiplicative --progress <float>: 0.5 is <= 1.0: adding 1.0
Num weight bits = 18
learning rate = 0.5
initial_t = 0
power_t = 0.5
using no cache
Reading datafile = train-sets/0001.dat
num sources = 1
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
1.000000 1.000000            1            1.0   1.0000   0.0000       51
0.513608 0.027217            2            2.0   0.0000   0.1650      104
0.349744 0.022014            3            3.0   0.0000   0.1484       57
0.211116 0.003174            5            5.0   0.0000   0.0558      131
0.237730 0.282086            8            8.0   0.0000   0.2023      146
0.217912 0.178276           12           12.0   0.0000   0.2455      209
0.249524 0.312749           18           18.0   0.0000   0.2879       29
0.246787 0.241314           27           27.0   0.0000   0.2217      197
0.225391 0.184126           41           41.0   0.0000   0.2652       20
0.235019 0.253817           62           62.0   0.0000   0.4044       96
0.215739 0.177177           93           93.0   1.0000   0.9319       58
0.218314 0.223411          140          140.0   0.0000   0.3487       82

finished run
number of examples per pass = 200
passes used = 1
weighted example sum = 200.000000
weighted label sum = 91.000000
average loss = 0.195768
best constant = 0.455000
best constant's loss = 0.247975
total feature number = 15482
