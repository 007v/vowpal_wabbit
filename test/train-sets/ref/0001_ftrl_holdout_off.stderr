using l1 regularization = 2
final_regressor = models/0001_ftrl.model
Enabling FTRL based optimization
Algorithm used: Proximal-FTRL
ftrl_alpha = 0.01
ftrl_beta = 0
Num weight bits = 18
learning rate = 0.5
initial_t = 0
power_t = 0.5
decay_learning_rate = 1
creating cache_file = train-sets/0001.dat.cache
Reading datafile = train-sets/0001.dat
num sources = 1
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
0.000000 0.000000            1            1.0   1.0000   1.0000       51
0.000000 0.000000            2            2.0   0.0000   0.0000      104
0.000000 0.000000            4            4.0   0.0000   0.0000      135
0.125000 0.250000            8            8.0   0.0000   0.0000      146
0.247589 0.370177           16           16.0   1.0000   0.0126       24
0.301587 0.355586           32           32.0   0.0000   0.0386       32
0.320360 0.339132           64           64.0   0.0000   0.0653       61
0.357457 0.394554          128          128.0   1.0000   0.1067      106
0.352506 0.347555          256          256.0   0.0000   0.1645       71
0.328052 0.303599          512          512.0   0.0000   0.2267       49
0.295738 0.263424         1024         1024.0   1.0000   0.3361       31

finished run
number of examples = 2000
weighted example sum = 2000.000000
weighted label sum = 910.000000
average loss = 0.255706
best constant = 0.455000
best constant's loss = 0.247975
total feature number = 154820
