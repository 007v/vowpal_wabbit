Num weight bits = 18
learning rate = 0.5
initial_t = 0
power_t = 0.5
using no cache
Reading datafile = train-sets/0001.dat
num sources = 1
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
0.000000 0.000000            1            1.0   1.0000   1.0000       51
0.172320 0.344641            2            2.0   0.0000   0.5871      104
0.086160 0.000000            4            4.0   0.0000   0.0000      135
0.083877 0.081593            8            8.0   0.0000   0.0000      146
0.073030 0.062183           16           16.0   1.0000   1.0000       24
0.063186 0.053341           32           32.0   0.0000   0.0113       32
0.080969 0.098752           64           64.0   0.0000   0.0000       61
0.080713 0.080457          128          128.0   1.0000   1.0000      106

finished run
number of examples per pass = 200
passes used = 1
weighted example sum = 200.000000
weighted label sum = 91.000000
average loss = 0.072308
best constant = 0.455000
best constant's loss = 0.247975
total feature number = 15482
