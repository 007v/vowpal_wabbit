using l1 regularization = 0.9
final_regressor = models/0001_ftrl.model
Enabling FTRL based optimization
Algorithm used: Proximal-FTRL
ftrl_alpha = 3
ftrl_beta = 0
Num weight bits = 18
learning rate = 0.5
initial_t = 0
power_t = 0.5
decay_learning_rate = 1
creating cache_file = train-sets/0001.dat.cache
Reading datafile = train-sets/0001.dat
num sources = 1
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
0.000000 0.000000            1            1.0   1.0000   1.0000       51
0.000000 0.000000            2            2.0   0.0000   0.0000      104
0.000000 0.000000            4            4.0   0.0000   0.0000      135
0.250000 0.500000            8            8.0   0.0000   0.0000      146
0.187500 0.125000           16           16.0   1.0000   1.0000      143
0.343919 0.500338           32           32.0   1.0000   0.0001       70
0.369976 0.396033           64           64.0   0.0000   0.0157       34
0.370868 0.371761          128          128.0   0.0000   0.4200       30
0.256543 0.142217          256          256.0   0.0000   0.2154       72
0.153629 0.050716          512          512.0   0.0000   0.0000       37
0.079788 0.005947         1024         1024.0   1.0000   0.8567       94

finished run
number of examples = 1440
weighted example sum = 1440.000000
weighted label sum = 640.000000
average loss = 0.103425 h
best constant = 0.444444
best constant's loss = 0.246914
total feature number = 110264
