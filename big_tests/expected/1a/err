final_regressor = mnist.model
Num weight bits = 24
learning rate = 0.1
initial_t = 0
power_t = 0.5
decay_learning_rate = 1
creating cache_file = mnist.cache
Reading datafile = /home/melamed/projects/vwDMFork/big_tests/dataSets/mnist.dir/train.prep
num sources = 1
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
1.000000 1.000000            1            1.0        5        1      136
1.000000 1.000000            2            2.0        8        5      147
0.750000 0.500000            4            4.0        2        5       94
0.875000 1.000000            8            8.0        8        5       98
0.812500 0.750000           16           16.0        1        1      166
0.656250 0.500000           32           32.0       10        2      139
0.562500 0.468750           64           64.0        7        7      194
0.476562 0.390625          128          128.0        3        3      179
0.417969 0.359375          256          256.0        2        2      118
0.320312 0.222656          512          512.0        4        4      182
0.262695 0.205078         1024         1024.0        2        2      114
0.221680 0.180664         2048         2048.0       10       10      132
0.177734 0.133789         4096         4096.0        7        7      151
0.147217 0.116699         8192         8192.0        2        2       81
0.125732 0.104248        16384        16384.0        9        9      176
0.104401 0.083069        32768        32768.0        5        5      138
0.083542 0.062683        65536        65536.0        2        2       76
0.062805 0.042068       131072       131072.0        8        8      151
0.044857 0.026909       262144       262144.0        4        4      176
0.029736 0.014614       524288       524288.0        1        1      193
0.017325 0.004915      1048576      1048576.0        1        1      203

finished run
number of examples per pass = 60000
passes used = 24
weighted example sum = 1440000.000000
weighted label sum = 0.000000
average loss = 0.012981
total feature number = 217299744
